{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sketch to Photograph AI Image Generator\n",
    "\n",
    "### Made using numpy and cv2, no ML libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from ImageProcessing_Ege import imgpro as ege\n",
    "import cv2\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image class contains functions to process the images and turn them into data as needed by the ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Image:\n",
    "    def __init__(self, filename: str, image: np.ndarray = None):\n",
    "        \"\"\"\n",
    "        Loads an image from the given filename as a cv2 image object.\n",
    "        Usage: Image(\"filename\") or Image(\"filename.jpg\") or Image(\"filename.png\")\n",
    "        \"\"\"\n",
    "        self.filename = filename\n",
    "        if isinstance(image, np.ndarray):\n",
    "            self.image = image\n",
    "            self.shape = image.shape\n",
    "            return\n",
    "        elif isinstance(image, Image):\n",
    "            self.image = image.image\n",
    "            self.shape = image.shape\n",
    "            return\n",
    "        self.shape = None\n",
    "        self.image = None\n",
    "        try:\n",
    "            self.image = cv2.imread(filename)\n",
    "            self.shape = self.image.shape\n",
    "        except FileNotFoundError:\n",
    "            if filename[-4:] == \".jpg\" or filename[-4:] == \".png\":\n",
    "                print(\"Invalid filename\")\n",
    "                return\n",
    "            try:\n",
    "                self.image = cv2.imread(filename + \".jpg\")\n",
    "                self.shape = self.image.shape\n",
    "            except FileNotFoundError:\n",
    "                try:\n",
    "                    self.image = cv2.imread(filename + \".png\")\n",
    "                    self.shape = self.image.shape\n",
    "                except FileNotFoundError:\n",
    "                    print(\"Invalid filename\")\n",
    "    \n",
    "    def show(self, tabname: str = \"Image\"):\n",
    "        cv2.imshow(tabname, self.image)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "    \n",
    "    def save(self, newfilename: str):\n",
    "        if newfilename[-4:] != \".jpg\" and newfilename[-4:] != \".png\":\n",
    "            newfilename += \".png\"\n",
    "        cv2.imwrite(newfilename, self.image)\n",
    "        \n",
    "    def simplify(self, threshold: float):\n",
    "        \"\"\"\n",
    "        Simplifies the image by the threshold, using the Simplify_cv2 function from ImageProcessing_Ege.\n",
    "        \n",
    "        Returns an Image object.\n",
    "        \"\"\"\n",
    "        height, width = self.image.shape[:2]\n",
    "        contrasted = ege.create_contrast_matrix_cv2(self.image)\n",
    "        res = np.zeros((height, width, 3), dtype = np.uint8)\n",
    "        for x in range(width):\n",
    "            for y in range(height):\n",
    "                if contrasted[x, y] >= threshold:\n",
    "                    res[y, x] = np.array([0, 0, 0], dtype=np.uint8)\n",
    "                else:\n",
    "                    res[y, x] = np.array([255, 255, 255], dtype=np.uint8)\n",
    "        return Image(self.filename + \"_simplified_\" + str(threshold), res)\n",
    "    \n",
    "    def simplify_multiple(self, thresholds: list = [25, 50, 75, 100, 125, 150, 175, 200, 225, 250]):\n",
    "        \"\"\"\n",
    "        Simplifies the image by each threshold in the thresholds list of floats, returns a list of image objects.\n",
    "        \"\"\"\n",
    "        height, width = self.image.shape[:2]\n",
    "        contrasted = ege.create_contrast_matrix_cv2(self.image)\n",
    "        res = []\n",
    "        for i in range(len(thresholds)):\n",
    "            temp = np.zeros((height, width, 3), dtype = np.uint8)\n",
    "            for x in range(width):\n",
    "                for y in range(height):\n",
    "                    if contrasted[x, y] >= thresholds[i]:\n",
    "                        temp[y, x] = np.array([0, 0, 0], dtype=np.uint8)\n",
    "                    else:\n",
    "                        temp[y, x] = np.array([255, 255, 255], dtype=np.uint8)\n",
    "            res.append(Image(self.filename + \"_simplified_\" + str(thresholds[i]), temp))\n",
    "        return res\n",
    "    \n",
    "    def convert_data(self) -> list:\n",
    "        \"\"\"\n",
    "        Converts the BGR (not rgb because opencv uses bgr by default) image \n",
    "        into a list of 3 arrays of floats between 0 and 1, each array representing a color value (B, G, R)\n",
    "        \n",
    "        0 being 0 and 1 being 255\n",
    "        \"\"\"\n",
    "        res = []\n",
    "        height = self.shape[0]\n",
    "        for i in range(3):\n",
    "            temp = np.array([], dtype = np.float16)\n",
    "            for y in range(height):\n",
    "                temp = np.append(temp, (self.image[y, :, i]/255).astype(np.float16))\n",
    "            res.append(temp)\n",
    "        return res\n",
    "    \n",
    "    def convert_simplified_data(self) -> list:\n",
    "        \"\"\"\n",
    "        Converts the simplified image into an array of floats between 0 and 1\n",
    "        \n",
    "        0 being 0 and 1 being 1\n",
    "        \"\"\"\n",
    "        res = []\n",
    "        img = cv2.cvtColor(self.image, cv2.COLOR_BGR2GRAY)\n",
    "        height = self.shape[0]\n",
    "        for y in range(height):\n",
    "            res = np.append(res, (img[y]/255).astype(np.float16))\n",
    "        return res\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NeuralNetwork class contains functions to handle the ML model, for training and saving weights and biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "class NeuralNetwork:\n",
    "    def __init__(self, weights: list = [], biases: list = []):\n",
    "        self.weights = weights\n",
    "        self.biases = biases\n",
    "        \n",
    "    def init_params(self, layer_count: int, input_size: int, hidden_size: int = 100):\n",
    "        \"\"\"\n",
    "        Initializes the weights and biases of the neural network.\n",
    "        \n",
    "        DO NOT use if this class already has weights and biases assigned, it will reset them.\n",
    "        \"\"\"\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "        for i in range(layer_count):\n",
    "            if i == 0:\n",
    "                self.weights.append((np.random.rand(hidden_size, input_size)-0.5).astype(np.float16))\n",
    "                self.biases.append((np.random.rand(hidden_size, 1)-0.5).astype(np.float16))\n",
    "            elif i == layer_count - 1:\n",
    "                self.weights.append((np.random.rand(input_size, hidden_size)-0.5).astype(np.float16))\n",
    "                self.biases.append((np.random.rand(input_size, 1)-0.5).astype(np.float16))\n",
    "            else:\n",
    "                self.weights.append((np.random.rand(hidden_size, hidden_size)-0.5).astype(np.float16))\n",
    "                self.biases.append((np.random.rand(hidden_size, 1)-0.5).astype(np.float16))\n",
    "    \n",
    "    def sigmoid(self, x: np.ndarray):\n",
    "        return 255 / (1 + np.exp(-x/50))\n",
    "    \n",
    "    def ReLU(self, x: np.ndarray):\n",
    "        return np.maximum(0, x)\n",
    "        \n",
    "    def forward_propagation(self, inp: np.ndarray):\n",
    "        \"\"\"\n",
    "        Forward propagation algorithm to compute the output of the neural network.\n",
    "        \n",
    "        Parameters:\n",
    "        - inp: Input data.\n",
    "        \n",
    "        Returns:\n",
    "        - Z: List of linear combinations for each layer (excluding input layer).\n",
    "        - A: List of activation values for each layer (excluding input layer).\n",
    "        \"\"\"\n",
    "        if len(inp.shape) == 1:\n",
    "            A = [inp.reshape(inp.shape[0], 1)]\n",
    "        else:\n",
    "            A = [inp]\n",
    "        Z = []\n",
    "        for i in range(min(len(self.weights), len(self.biases))):\n",
    "            Z.append(np.dot(self.weights[i], A[-1]) + self.biases[i])\n",
    "            A.append(self.sigmoid(Z[-1]))\n",
    "        return Z, A[1:]\n",
    "        # TODO maybe change activation function, could add an option to choose although that will require retraining\n",
    "        \n",
    "    def predict(self, inp: np.ndarray):\n",
    "        \"\"\"\n",
    "        Returns the output of the neural network for the given input.\n",
    "        \"\"\"\n",
    "        Z, A = self.forward_propagation(inp)\n",
    "        return A[-1]\n",
    "    \n",
    "    def backward_propagation(self, A, Z, inp, out):\n",
    "        \"\"\"\n",
    "        Backpropagation algorithm to compute gradients for weights and biases.\n",
    "    \n",
    "        Parameters:\n",
    "        - A: List of activation values for each layer (excluding input layer).\n",
    "        - Z: List of linear combinations for each layer (excluding input layer).\n",
    "        - inp: Input data.\n",
    "        - out: Expected output data.\n",
    "    \n",
    "        Returns:\n",
    "        - dW: List of gradients for weight matrices.\n",
    "        - dB: List of gradients for bias vectors.\n",
    "        \"\"\"\n",
    "        W = self.weights\n",
    "        #m = inp.shape[0]\n",
    "        m = 10**8\n",
    "    \n",
    "        dZ = [0 for z in Z]\n",
    "        dW = [0 for w in W]\n",
    "        dB = [0 for b in self.biases]\n",
    "    \n",
    "        dZ[-1] = A[-1] - out\n",
    "        dW[-1] = (1 / m) * np.dot(dZ[2], A[1].T)\n",
    "        dB[-1] = (1 / m) * np.sum(dZ[2])\n",
    "        \n",
    "        for i in range(len(W) - 2, 0, -1):\n",
    "            dZ[i] = np.dot(W[i+1].T, dZ[i+1]) * (Z[i] > 0)\n",
    "            dW[i] = (1 / m) * np.dot(dZ[i], A[i-1].T)\n",
    "            dB[i] = (1 / m) * np.sum(dZ[i])\n",
    "            \n",
    "        dZ[0] = np.dot(W[1].T, dZ[1]) * (Z[0] > 0)\n",
    "        dW[0] = (1 / m) * np.dot(dZ[0], inp.T)\n",
    "        dB[0] = (1 / m) * np.sum(dZ[0])\n",
    "        \n",
    "        return dW, dB\n",
    "\n",
    "    def update_params(self, dW, dB, learning_rate: float = 0.1):\n",
    "        \"\"\"\n",
    "        Updates the weights and biases of the neural network.\n",
    "        \"\"\"\n",
    "        for i in range(min(len(self.weights), len(self.biases))):\n",
    "            self.weights[i] = (self.weights[i] - (dW[i] * learning_rate)).astype(np.float16)\n",
    "            self.biases[i] = (self.biases[i] - (dB[i] * learning_rate)).astype(np.float16)\n",
    "    \n",
    "    def train(self, inp: np.ndarray, expected_output: np.ndarray, epochs: int = 100, learning_rate: float = 0.1):\n",
    "        \"\"\"\n",
    "        Trains the neural network for the given input and expected output.\n",
    "        \"\"\"\n",
    "        print(\"Training started\")\n",
    "        for i in range(epochs):\n",
    "            \n",
    "            Z, A = self.forward_propagation(inp)\n",
    "            #print(\"Forward propagation done\")\n",
    "            \n",
    "            dW, dB = self.backward_propagation(A, Z, inp, expected_output)\n",
    "            #print(\"Backward propagation done\")\n",
    "            \n",
    "            self.update_params(dW, dB, learning_rate)\n",
    "            #print(\"Parameters updated\")\n",
    "            \n",
    "            output = self.predict(inp)\n",
    "            error = np.mean(np.abs(expected_output - output))\n",
    "            \n",
    "            \"\"\"\n",
    "            print(\"---------------inp-----------------\")\n",
    "            print(inp)\n",
    "            print(np.mean(inp))\n",
    "            print(\"---------------out-----------------\")\n",
    "            print(output)\n",
    "            print(np.mean(output))\n",
    "            print(\"---------------expected_output-----------------\")\n",
    "            print(expected_output)\n",
    "            print(np.mean(expected_output))\n",
    "            print(\"---------------error-----------------\")\n",
    "            print(error)\n",
    "            print(\"---------------end-----------------\")\"\"\"\n",
    "            \n",
    "            \n",
    "            #print(f\"Epoch {i+1} done, loss: {round(error, 3)}\")\n",
    "            if (i + 1) % 10 == 0:\n",
    "                print(f\"Epoch {i+1} loss: {round(error, 3)}\")\n",
    "        print(\"Final error: \" + str(round(error, 3)))\n",
    "        return error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = np.array([[1,2,3], [4,5,6], [7,8,9]])\n",
    "test2 = np.array([[2,2,2], [2,2,2], [2,2,2]])\n",
    "\n",
    "np.mean(np.abs(test1 - test2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some extra functions to turn back data into image class objects and create training data from a directory path with images in it.\n",
    "\n",
    "### Creates training data by simplifying each image by each threshold in the given parameter, and saving them in a list containing the training input and expected output for each color's neural network (B, G, R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_to_image(data: list, shape: tuple, newfilename: str = \"Data2Img_\" + str(int(time.time()*10000 % 10000))):\n",
    "    \"\"\"\n",
    "    Converts the given data back to an image.\n",
    "    \"\"\"\n",
    "    res = np.zeros((shape[0], shape[1], 3), dtype = np.uint8)\n",
    "    for y in range(shape[0]):\n",
    "        for x in range(shape[1]):\n",
    "            #res[y, x] = np.array([data[0][y * shape[1] + x][0]*255, data[1][y * shape[1] + x][0]*255, data[2][y * shape[1] + x][0]*255], dtype=np.uint8)\n",
    "            res[y, x] = np.array([data[0][y * shape[1] + x][0], data[1][y * shape[1] + x][0], data[2][y * shape[1] + x][0]], dtype=np.uint8)\n",
    "    return Image(newfilename, res)\n",
    "\n",
    "def simplified_data_to_image(data: list, shape: tuple, newfilename: str = \"Data2Img_\" + str(int(time.time()*10000 % 10000))):\n",
    "    \"\"\"\n",
    "    Converts the given data back to an image.\n",
    "    \"\"\"\n",
    "    res = np.zeros((shape[0], shape[1], 3), dtype = np.uint8)\n",
    "    for y in range(shape[0]):\n",
    "        for x in range(shape[1]):\n",
    "            if data[y * shape[1] +  x] == 0:\n",
    "                res[y, x] = np.array([0, 0, 0], dtype=np.uint8)\n",
    "            else:\n",
    "                res[y, x] = np.array([255, 255, 255], dtype=np.uint8)\n",
    "    return Image(newfilename, res)\n",
    "        \n",
    "        \n",
    "def create_training_data(path: str, thresholds: list = [25, 50, 75, 100, 125, 150, 175, 200, 225, 250]):\n",
    "    \"\"\"\n",
    "    Imports all of the images in the given path, simplifies them by the given thresholds, and converts them to data.\n",
    "    \n",
    "    Returns list of lists of input arrays and output arrays for example:\n",
    "    \n",
    "    inputs = [img1_25, img1_50, ... , img2_25, img2_50, ...]]\n",
    "    \n",
    "    outputsB = [img1B,   img1B,    ... , img2B,    img2B, ...]\n",
    "    outputsG = [img1G,   img1G,    ... , img2G,    img2G, ...]\n",
    "    outputsR = [img1R,   img1R,    ... , img2R,    img2R, ...]\n",
    "    \n",
    "    res = [inputs, outputsB, outputsG, outputsR]\n",
    "    \"\"\"\n",
    "    print(os.listdir(path))\n",
    "    res = [[], [], [], []]\n",
    "    for filename in os.listdir(path):\n",
    "        if filename[-4:] == \".jpg\" or filename[-4:] == \".png\":\n",
    "            img = Image(path + \"\\\\\" + filename)\n",
    "            data = img.convert_data()\n",
    "            B_data = data[0]\n",
    "            G_data = data[1]\n",
    "            R_data = data[2]\n",
    "            simples = img.simplify_multiple(thresholds)\n",
    "            \n",
    "            for s in simples:\n",
    "                s_data = s.convert_simplified_data()\n",
    "                res[0].append(s_data)\n",
    "                res[1].append(B_data)\n",
    "                res[2].append(G_data)\n",
    "                res[3].append(R_data)\n",
    "                \n",
    "    res[0] = np.array(res[0]).T\n",
    "    res[1] = np.array(res[1]).T\n",
    "    res[2] = np.array(res[2]).T\n",
    "    res[3] = np.array(res[3]).T\n",
    "    return res\n",
    "\n",
    "\n",
    "def combine_colors(B: np.ndarray, G: np.ndarray, R: np.ndarray, shape: tuple):\n",
    "    \"\"\"\n",
    "    Combines the given color values together and returns the resulting image.\n",
    "    \"\"\"\n",
    "    return data_to_image([B, G, R], shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating training data from the test directory /train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = create_training_data(\"Birds/train/ABBOTTS BABBLER/\")\n",
    "print(\"Training data created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, b, g, r = res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a = input(\"Enter folder path: \")\n",
    "#a = \"train\"\n",
    "#res = create_training_data(a)\n",
    "#print(\"Training data created\")\n",
    "\n",
    "nnB = NeuralNetwork()\n",
    "nnG = NeuralNetwork()\n",
    "nnR = NeuralNetwork()\n",
    "print(\"Neural Networks created\")\n",
    "\n",
    "nnB.init_params(3, inputs.shape[0])\n",
    "nnG.init_params(3, inputs.shape[0])\n",
    "nnR.init_params(3, inputs.shape[0])\n",
    "print(\"Weights and biases initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just checking if the weights and biases and input shapes match as intended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f\"{nnB.weights[0].shape} * {inputs.shape} + {nnB.biases[0].shape} = {(np.dot(nnB.weights[0], inputs) + nnB.biases[0]).shape}\", f\"{nnB.weights[1].shape} * {(np.dot(nnB.weights[0], inputs) + nnB.biases[0]).shape} + {nnB.biases[1].shape} = {(np.dot(nnB.weights[1], np.dot(nnB.weights[0], inputs) + nnB.biases[0]) + nnB.biases[1]).shape}\", f\"{nnB.weights[2].shape} * {(np.dot(nnB.weights[1], np.dot(nnB.weights[0], inputs) + nnB.biases[0]) + nnB.biases[1]).shape} + {nnB.biases[2].shape} = {(np.dot(nnB.weights[2], np.dot(nnB.weights[1], np.dot(nnB.weights[0], inputs) + nnB.biases[0]) + nnB.biases[1]) + nnB.biases[2]).shape}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing before training, should normally create random noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_rgb_image(image, title=None, conversion=cv2.COLOR_BGR2RGB):\n",
    "\n",
    "    image = cv2.cvtColor(image, conversion)\n",
    "\n",
    "    plt.imshow(image)\n",
    "\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Neural networks trained\")\n",
    "    \n",
    "print(\"Test run\")\n",
    "\n",
    "test = Image(\"test.png\")\n",
    "expected = Image(\"test.jpg\")\n",
    "testdata = test.convert_simplified_data()\n",
    "B = nnB.predict(testdata)\n",
    "G = nnG.predict(testdata)\n",
    "R = nnR.predict(testdata)\n",
    "\n",
    "result = combine_colors(B, G, R, test.shape)\n",
    "x, y = 85, 153\n",
    "result.image[y,x], B[y*result.image.shape[1] + x], G[y*result.image.shape[1] + x], R[y*result.image.shape[1] + x]\n",
    "#result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_rgb_image(test.image, \"Input\")\n",
    "show_rgb_image(expected.image, \"Expected result\")\n",
    "show_rgb_image(result.image, \"Untrained result, random noise\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(nnB.weights[0]), np.mean(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.dot(nnB.weights[0], inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_e = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = 10\n",
    "l = 0.5\n",
    "\n",
    "lossB = nnB.train(inputs, b*255, e, l)\n",
    "print(\"Blue trained\")\n",
    "lossG = nnG.train(inputs, g*255, e, l)\n",
    "print(\"Green trained\")\n",
    "lossR = nnR.train(inputs, r*255, e, l)\n",
    "print(\"Red trained\")\n",
    "\n",
    "total_e += e\n",
    "\n",
    "print(f\"Loss: {(lossB + lossG + lossR) / 3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Neural networks trained\")\n",
    "    \n",
    "print(\"Test run\")\n",
    "\n",
    "test = Image(\"test.png\")\n",
    "expected = Image(\"test.jpg\")\n",
    "testdata = test.convert_simplified_data()\n",
    "B = nnB.predict(testdata)\n",
    "G = nnG.predict(testdata)\n",
    "R = nnR.predict(testdata)\n",
    "\n",
    "result = combine_colors(B, G, R, test.shape)\n",
    "x, y = 85, 153\n",
    "result.image[y,x], B[y*result.image.shape[1] + x], G[y*result.image.shape[1] + x], R[y*result.image.shape[1] + x]\n",
    "#result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(B), np.mean(G), np.mean(R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(expected.image[:,:,0]), np.mean(expected.image[:,:,1]), np.mean(expected.image[:,:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(expected.image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_rgb_image(test.image, \"Input\")\n",
    "show_rgb_image(expected.image, \"Expected result\")\n",
    "show_rgb_image(result.image, f\"Trained result, {total_e} epochs, {l} learning rate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
